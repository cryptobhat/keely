package com.kannada.kavi.features.suggestion.models

/**
 * Prediction - ML-based next-word prediction result
 *
 * Represents a word predicted by the machine learning model along with
 * its confidence score and the context that was used to make the prediction.
 *
 * This is different from a Suggestion in that:
 * - Prediction: Generated by ML model based on typing context
 * - Suggestion: Can come from multiple sources (dictionary, history, ML, typo correction)
 *
 * WHAT IS IT?
 * ===========
 * A Prediction is what the neural network thinks you'll type next.
 *
 * Example:
 * You type: "I am going to"
 * Context: ["I", "am", "going"]
 * ML Model predicts:
 *   1. Prediction(word="the", confidence=0.78, contextUsed=["I", "am", "going"])
 *   2. Prediction(word="be", confidence=0.65, contextUsed=["I", "am", "going"])
 *   3. Prediction(word="have", confidence=0.52, contextUsed=["I", "am", "going"])
 *
 * CONFIDENCE SCORE:
 * =================
 * - 0.0 to 1.0 range
 * - 0.9+ : Very confident (almost certain)
 * - 0.7-0.9 : Confident (likely correct)
 * - 0.5-0.7 : Moderate confidence (possible)
 * - 0.3-0.5 : Low confidence (less likely)
 * - < 0.3 : Very low confidence (usually filtered out)
 *
 * CONTEXT:
 * ========
 * The context is the previous words that the model used to make the prediction.
 * Most models use last 2-4 words for context.
 *
 * Example contexts:
 * - ["ನಾನು", "ಮನೆಗೆ", "ಹೋಗುತ್ತಿದ್ದೇನೆ"] → predicts next word
 * - ["I", "am", "going"] → predicts next word
 * - ["good", "morning"] → predicts next word
 *
 * @property word The predicted word
 * @property confidence Confidence score (0.0 to 1.0)
 * @property contextUsed The words used as context for this prediction
 * @property modelVersion Optional: Version of ML model that made this prediction
 * @property timestamp Optional: When this prediction was made (for analytics)
 */
data class Prediction(
    val word: String,
    val confidence: Float,
    val contextUsed: List<String>,
    val modelVersion: String? = null,
    val timestamp: Long = System.currentTimeMillis()
) {
    init {
        require(word.isNotBlank()) { "Prediction word cannot be blank" }
        require(confidence in 0.0f..1.0f) { "Confidence must be between 0.0 and 1.0, got $confidence" }
        require(contextUsed.isNotEmpty()) { "Context cannot be empty" }
    }

    /**
     * Convert to Suggestion for use in SuggestionEngine
     *
     * Predictions from ML are converted to Suggestions so they can be
     * combined with dictionary/history suggestions and ranked together.
     */
    fun toSuggestion(): Suggestion {
        return Suggestion(
            word = word,
            confidence = confidence,
            source = SuggestionSource.PREDICTION,
            frequency = 0  // ML predictions don't have frequency
        )
    }

    /**
     * Get confidence level as human-readable string
     */
    fun getConfidenceLevel(): String {
        return when {
            confidence >= 0.9f -> "Very High"
            confidence >= 0.7f -> "High"
            confidence >= 0.5f -> "Medium"
            confidence >= 0.3f -> "Low"
            else -> "Very Low"
        }
    }

    /**
     * Check if this prediction meets minimum confidence threshold
     */
    fun meetsThreshold(minConfidence: Float): Boolean {
        return confidence >= minConfidence
    }

    override fun toString(): String {
        return "Prediction(word='$word', confidence=${"%.2f".format(confidence)}, context=${contextUsed.joinToString(", ")})"
    }
}

/**
 * PredictionBatch - A batch of predictions for the same context
 *
 * Used when the ML model returns multiple predictions at once.
 * This is more efficient than making multiple single predictions.
 *
 * @property predictions List of predictions, ordered by confidence (highest first)
 * @property context The context used for all predictions in this batch
 * @property inferenceTimeMs How long the ML inference took
 */
data class PredictionBatch(
    val predictions: List<Prediction>,
    val context: List<String>,
    val inferenceTimeMs: Long
) {
    /**
     * Get top N predictions
     */
    fun topN(n: Int): List<Prediction> {
        return predictions.take(n)
    }

    /**
     * Filter predictions by minimum confidence
     */
    fun filterByConfidence(minConfidence: Float): List<Prediction> {
        return predictions.filter { it.confidence >= minConfidence }
    }

    /**
     * Get only high-confidence predictions (>= 0.7)
     */
    fun highConfidencePredictions(): List<Prediction> {
        return predictions.filter { it.confidence >= 0.7f }
    }

    /**
     * Convert all predictions to suggestions
     */
    fun toSuggestions(): List<Suggestion> {
        return predictions.map { it.toSuggestion() }
    }

    /**
     * Check if inference was fast enough
     */
    fun isFastEnough(maxTimeMs: Long): Boolean {
        return inferenceTimeMs <= maxTimeMs
    }

    override fun toString(): String {
        return """
            PredictionBatch(
                count=${predictions.size},
                context=${context.joinToString(", ")},
                time=${inferenceTimeMs}ms,
                topPrediction=${predictions.firstOrNull()?.word ?: "none"}
            )
        """.trimIndent()
    }
}

/**
 * USAGE EXAMPLES:
 * ==============
 *
 * Example 1: Single prediction
 * ```kotlin
 * val prediction = Prediction(
 *     word = "ನಮಸ್ತೆ",
 *     confidence = 0.85f,
 *     contextUsed = listOf("ಹಲೋ", "ನನ್ನ")
 * )
 *
 * println(prediction)
 * // Output: Prediction(word='ನಮಸ್ತೆ', confidence=0.85, context=ಹಲೋ, ನನ್ನ)
 *
 * println(prediction.getConfidenceLevel())
 * // Output: High
 *
 * val suggestion = prediction.toSuggestion()
 * // Can now be used with other suggestions
 * ```
 *
 * Example 2: Batch of predictions
 * ```kotlin
 * val batch = PredictionBatch(
 *     predictions = listOf(
 *         Prediction("the", 0.78f, listOf("I", "am", "going")),
 *         Prediction("be", 0.65f, listOf("I", "am", "going")),
 *         Prediction("have", 0.52f, listOf("I", "am", "going"))
 *     ),
 *     context = listOf("I", "am", "going"),
 *     inferenceTimeMs = 35
 * )
 *
 * // Get top 2 predictions
 * val top2 = batch.topN(2)
 * // [Prediction("the", 0.78), Prediction("be", 0.65)]
 *
 * // Filter by confidence
 * val confident = batch.filterByConfidence(0.6f)
 * // [Prediction("the", 0.78), Prediction("be", 0.65)]
 *
 * // Check performance
 * if (batch.isFastEnough(50)) {
 *     println("Inference was fast!")
 * }
 * ```
 *
 * Example 3: Using with SuggestionEngine
 * ```kotlin
 * // In SuggestionEngine.getSuggestions()
 * val suggestions = mutableListOf<Suggestion>()
 *
 * // Get dictionary suggestions
 * suggestions.addAll(getDictionarySuggestions(currentWord))
 *
 * // Get ML predictions
 * val context = contextManager.getContext(3)
 * val mlResult = mlPredictor.predict(context)
 *
 * if (mlResult is Result.Success) {
 *     val batch = mlResult.data
 *
 *     // Filter and convert to suggestions
 *     val mlSuggestions = batch
 *         .filterByConfidence(Constants.ML.MIN_PREDICTION_CONFIDENCE)
 *         .toSuggestions()
 *
 *     suggestions.addAll(mlSuggestions)
 * }
 *
 * // Sort all suggestions by confidence
 * return suggestions
 *     .sortedByDescending { it.confidence }
 *     .take(5)
 * ```
 *
 * IMPORTANT NOTES:
 * ================
 * 1. **Validation**: Constructor validates all inputs:
 *    - Word must not be blank
 *    - Confidence must be 0.0-1.0
 *    - Context must not be empty
 *
 * 2. **Immutability**: Data class is immutable (val properties)
 *    - Thread-safe
 *    - Can be safely shared across coroutines
 *
 * 3. **Conversion**: Easy conversion to Suggestion via toSuggestion()
 *    - Allows ML predictions to integrate with existing suggestion system
 *    - Sets source to PREDICTION for tracking
 *
 * 4. **Timestamp**: Automatically captures when prediction was made
 *    - Useful for analytics
 *    - Helps detect stale predictions
 */
